{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from scipy.spatial.distance import cosine\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "print(\"imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Face-encodings for all faces and store it in a CSV file\n",
    "\n",
    "Get Encodings for all images and store in a CSV file. With name and Encodings\n",
    "Note: I've got only one image per a  person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "\n",
    "1. Loop over folder's contents\n",
    "2. For each file , get encodings\n",
    "3. In a CSV file, save file name, encodings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Name, Encodings]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#create an empty dataframe \n",
    "data = {'Name':  [],\n",
    "        'Encodings' : []\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame (data, columns = ['Name','Encodings'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encodings_CSV_path = \"\"\n",
    "folder_path = \"C:\\\\MyLearnings\\\\DeepLearning\\\\Facial Projects\\\\Face Recognition\\\\SingleShotDataset\\\\*.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Dakshayani\n",
      "0\n",
      "        0         1         2         3         4        5         6    \\\n",
      "0 -0.094346  0.030154  0.104514 -0.017434 -0.049997 -0.05203  0.038582   \n",
      "\n",
      "        7         8         9    ...       118       119       120       121  \\\n",
      "0 -0.145181  0.224201 -0.140293  ... -0.018829  0.047649 -0.065139 -0.070123   \n",
      "\n",
      "        122       123       124       125       126       127  \n",
      "0 -0.090295 -0.055078  0.048481 -0.009668  0.046949 -0.015656  \n",
      "\n",
      "[1 rows x 128 columns]\n",
      "<class 'list'>\n",
      "Ramya\n",
      "1\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.094346  0.030154  0.104514 -0.017434 -0.049997 -0.052030  0.038582   \n",
      "1 -0.031513  0.046748  0.083386 -0.064198 -0.081684  0.006021  0.008460   \n",
      "\n",
      "        7         8         9    ...       118       119       120       121  \\\n",
      "0 -0.145181  0.224201 -0.140293  ... -0.018829  0.047649 -0.065139 -0.070123   \n",
      "1 -0.076569  0.215477 -0.194164  ...  0.028641  0.077017 -0.007868 -0.101604   \n",
      "\n",
      "        122       123       124       125       126       127  \n",
      "0 -0.090295 -0.055078  0.048481 -0.009668  0.046949 -0.015656  \n",
      "1 -0.144912 -0.080937  0.109795 -0.026641  0.096905 -0.020574  \n",
      "\n",
      "[2 rows x 128 columns]\n",
      "(2, 128)\n",
      "(2, 129)\n",
      "(2, 128)\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(folder_path)\n",
    "list_dicts = []\n",
    "name_list = []\n",
    "dfObj = pd.DataFrame(columns = ['Enc'])\n",
    "i = 0\n",
    "for file in files:\n",
    "    image = face_recognition.load_image_file(file)\n",
    "    encodings = face_recognition.face_encodings(image)[0]\n",
    "    encodings = encodings.tolist()\n",
    "    print(type(encodings))\n",
    "    list_dicts.append(encodings)\n",
    "    basename = os.path.basename(file)\n",
    "    name = basename[:-4]\n",
    "    print(name)\n",
    "    df2 = (name,encodings)\n",
    "    name_list.append(name) \n",
    "    dfObj1 = pd.Series(encodings)\n",
    "    dfObj.append(dfObj1,ignore_index=True)\n",
    "    print (i)\n",
    "    #list_dicts.append(df2)\n",
    "    dataffame = pd.DataFrame(list_dicts)\n",
    "    print(dataffame)\n",
    "    i+=1\n",
    "print(dataffame.shape)\n",
    "dataffame['name_list'] = pd.Series(name_list,index=dataffame.index)\n",
    "print(dataffame.shape)\n",
    "\n",
    "dataffame.set_index('name_list',inplace = True)\n",
    "print(dataffame.shape)\n",
    "\n",
    "# SAve it to a CSV file\n",
    "\n",
    "dataffame.to_csv(\"C:\\\\MyLearnings\\\\DeepLearning\\\\Facial Projects\\\\Face Recognition\\\\Encodings\\\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to recognise face in real time video\n",
    "\n",
    "Now, we're gonna read the csv file and store in the encodings to compare faces from each frame\n",
    "\n",
    "The FaceRecognition api has faceencodings of size 128 and hence for a person 1*128 size array is needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name_list         0         1         2         3         4         5  \\\n",
      "0  Dakshayani -0.094346  0.030154  0.104514 -0.017434 -0.049997 -0.052030   \n",
      "1       Ramya -0.031513  0.046748  0.083386 -0.064198 -0.081684  0.006021   \n",
      "\n",
      "          6         7         8  ...       118       119       120       121  \\\n",
      "0  0.038582 -0.145181  0.224201  ... -0.018829  0.047649 -0.065139 -0.070123   \n",
      "1  0.008460 -0.076569  0.215477  ...  0.028641  0.077017 -0.007868 -0.101604   \n",
      "\n",
      "        122       123       124       125       126       127  \n",
      "0 -0.090295 -0.055078  0.048481 -0.009668  0.046949 -0.015656  \n",
      "1 -0.144912 -0.080937  0.109795 -0.026641  0.096905 -0.020574  \n",
      "\n",
      "[2 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "# read csv file and load into a dataframe\n",
    "df = pd.read_csv(\"C:\\\\MyLearnings\\\\DeepLearning\\\\Facial Projects\\\\Face Recognition\\\\Encodings\\\\data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_encodings = []\n",
    "for i in range(len(df)):\n",
    "    list_encodings.append(df.iloc[i,1:].values.astype('float64'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "known_face_names = df['name_list']\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(list_encodings, face_encoding)\n",
    "            name = \"Unknown\"# unknown if not in the database\n",
    "\n",
    "            # # If a match was found in known_face_encodings, just use the first one.\n",
    "            # if True in matches:\n",
    "            #     first_match_index = matches.index(True)\n",
    "            #     name = known_face_names[first_match_index]\n",
    "\n",
    "            # Or instead, use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(list_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
